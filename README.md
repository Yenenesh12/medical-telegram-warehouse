# Telegram Medical Data Warehouse

A comprehensive data pipeline that scrapes medical content from Telegram channels, processes images with YOLO object detection, transforms data with dbt, and provides analytics through a FastAPI interface.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Telegram      â”‚â”€â”€â”€â–¶â”‚  PostgreSQL  â”‚â”€â”€â”€â–¶â”‚   dbt Models    â”‚
â”‚   Scraper       â”‚    â”‚   Raw Data   â”‚    â”‚ (Staging/Marts) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOLO Object    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   FastAPI       â”‚
â”‚  Detection      â”‚                          â”‚   Analytics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Dagster      â”‚
                    â”‚  Orchestration   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Option 1: Docker Compose (Recommended)
```bash
# Clone and navigate to project
git clone <https://github.com/Yenenesh12/medical-telegram-warehouse.git>
cd telegram-medical-warehouse

# Start all services
docker-compose up
```

**Services will be available at:**
- ğŸ¯ Dagster UI: http://localhost:3000
- ğŸ“Š API Documentation: http://localhost:8000/docs
- ğŸ—„ï¸ PostgreSQL: localhost:5432

### Option 2: Manual Setup

1. **Install Dependencies**
```bash
pip install -r requirements.txt
```

2. **Environment Configuration**
Create `.env` file:
```env


# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=telegram_warehouse
POSTGRES_USER=postgres
POSTGRES_PASSWORD=yene1995
```

3. **Initialize Database**
```bash
python scripts/init_database.py
```

4. **Run Pipeline**
```bash
python scripts/run_pipeline.py
```

## ğŸ“‹ Components

### 1. Data Ingestion
- **Telegram Scraper** (`src/scraper.py`): Extracts messages and media from Telegram channels
- **Database Loader** (`src/load_to_postgres.py`): Loads raw data into PostgreSQL

### 2. Computer Vision
- **YOLO Detection** (`src/yolo_detect.py`): Object detection on medical images
- **Results Loader** (`src/load_yolo_results.py`): Stores detection results

### 3. Data Transformation
- **dbt Models** (`medical_warehouse/models/`):
  - **Staging**: Clean and standardize raw data
  - **Marts**: Business-ready dimensional models

### 4. Analytics API
- **FastAPI Server** (`api/main.py`): RESTful API for data access
- **Endpoints**:
  - `/api/reports/top-products` - Top mentioned medical products
  - `/api/channels/{name}/activity` - Channel activity trends
  - `/api/search/messages` - Message search
  - `/api/reports/visual-content` - Visual content statistics

### 5. Orchestration
- **Dagster Pipeline** (`pipeline.py`): Automated workflow management
- **Scheduling**: Daily runs at 2 AM
- **Monitoring**: Web UI for pipeline status

## ğŸ› ï¸ Usage

### Running Individual Components

**Scrape Telegram Data:**
```bash
python scripts/run_scraper.py --days-back 7
```

**Run dbt Transformations:**
```bash
python scripts/run_dbt.py all
```

**Start Analytics API:**
```bash
python scripts/run_api.py
```

**Process Images with YOLO:**
```bash
python src/yolo_detect.py
```

### Pipeline Orchestration

**Interactive Pipeline Runner:**
```bash
python scripts/run_pipeline.py
```

**Dagster Web UI:**
```bash
dagster dev -f pipeline.py -h 0.0.0.0 -p 3000
```

## ğŸ“Š Data Models

### Raw Layer (`raw` schema)
- `telegram_messages`: Raw scraped messages
- `image_detections`: YOLO detection results

### Staging Layer (`staging` schema)
- `stg_channels`: Cleaned channel data
- `stg_telegram_messages`: Standardized messages

### Marts Layer (`marts` schema)
- `dim_channels`: Channel dimension
- `fct_messages`: Message facts
- `fct_image_detections`: Detection facts

## ğŸ”§ Configuration

### Database Schema
```sql
-- Schemas created automatically
CREATE SCHEMA raw;      -- Raw ingested data
CREATE SCHEMA staging;  -- Cleaned data
CREATE SCHEMA marts;    -- Business models
CREATE SCHEMA utils;    -- Utility functions
```

### dbt Configuration
- **Project**: `medical_warehouse/dbt_project.yml`
- **Profiles**: `medical_warehouse/profiles.yml`
- **Models**: `medical_warehouse/models/`

### Dagster Configuration
- **Pipeline**: `pipeline.py`
- **Config**: `dagster.yaml`
- **Schedule**: Daily at 2 AM (Africa/Addis_Ababa)

## ğŸ“ˆ Monitoring & Logging

### Dagster UI Features
- Pipeline execution history
- Asset lineage visualization
- Scheduling and sensors
- Error tracking and alerts

### Logging
- Application logs: `logs/`
- Pipeline execution logs in Dagster UI
- API access logs via FastAPI

## ğŸ§ª Testing

### dbt Tests
```bash
# Run all tests
python scripts/run_dbt.py test

# Run specific test
dbt test --select assert_no_future_messages
```

### API Testing
```bash
# Health check
curl http://localhost:8000/

# Get top products
curl http://localhost:8000/api/reports/top-products
```

## ğŸ“ Project Structure

```
telegram-medical-warehouse/
â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py            # API server
â”‚   â”œâ”€â”€ database.py        # Database connections
â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”œâ”€â”€ medical_warehouse/      # dbt project
â”‚   â”œâ”€â”€ models/            # Data models
â”‚   â”‚   â”œâ”€â”€ staging/       # Staging models
â”‚   â”‚   â””â”€â”€ marts/         # Business models
â”‚   â””â”€â”€ tests/             # dbt tests
â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â”œâ”€â”€ run_pipeline.py    # Pipeline runner
â”‚   â”œâ”€â”€ run_api.py         # API server
â”‚   â”œâ”€â”€ run_scraper.py     # Scraper runner
â”‚   â””â”€â”€ init_database.py   # Database setup
â”œâ”€â”€ src/                   # Core modules
â”‚   â”œâ”€â”€ scraper.py         # Telegram scraper
â”‚   â”œâ”€â”€ load_to_postgres.py # Data loader
â”‚   â”œâ”€â”€ yolo_detect.py     # Object detection
â”‚   â””â”€â”€ load_yolo_results.py # Results loader
â”œâ”€â”€ pipeline.py            # Dagster pipeline
â”œâ”€â”€ docker-compose.yml     # Docker services
â”œâ”€â”€ Dockerfile            # Container definition
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸ”’ Security & Privacy

- Telegram API credentials stored in environment variables
- Database connections use environment-based configuration
- No sensitive data committed to version control
- API endpoints can be secured with authentication (extend as needed)

## ğŸš¨ Troubleshooting

### Common Issues

**Database Connection Failed:**
```bash
# Check PostgreSQL is running
docker-compose ps postgres

# Check connection
python -c "import psycopg2; psycopg2.connect('postgresql://postgres:yene1995@localhost:5432/telegram_warehouse')"
```

**Telegram API Errors:**
- Verify API credentials in `.env`
- Check phone number format (+1234567890)
- Ensure Telegram account has access to target channels

**dbt Compilation Errors:**
```bash
# Check dbt configuration
dbt debug --profiles-dir medical_warehouse

# Compile models
dbt compile --profiles-dir medical_warehouse
```

**YOLO Detection Issues:**
- Ensure images exist in `data/raw/images/`
- Check YOLO model download (automatic on first run)
- Verify OpenCV installation

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ Support

For questions and support:
- Create an issue in the repository
- Check the troubleshooting section above
- Review Dagster logs in the web UI
- Check application logs in the `logs/` directory